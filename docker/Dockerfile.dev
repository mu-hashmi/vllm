# Development Dockerfile for vLLM
# This image allows installing vLLM from a git repository at runtime
# Build once, use with different branches via VLLM_REPO and VLLM_BRANCH env vars

ARG CUDA_VERSION=12.8.0
ARG PYTHON_VERSION=3.12
FROM nvidia/cuda:${CUDA_VERSION}-base-ubuntu22.04

ARG PYTHON_VERSION
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /workspace

# Install Python, CUDA dev tools, and build dependencies
RUN echo 'tzdata tzdata/Areas select America' | debconf-set-selections \
    && echo 'tzdata tzdata/Zones/America select Los_Angeles' | debconf-set-selections \
    && apt-get update -y \
    && apt-get install -y --no-install-recommends \
        software-properties-common \
        curl \
        git \
        build-essential \
        python3-pip \
        ffmpeg \
        libsm6 \
        libxext6 \
        libgl1 \
        libibverbs-dev \
    && for i in 1 2 3; do \
        add-apt-repository -y ppa:deadsnakes/ppa && break || \
        { echo "Attempt $i failed, retrying in 5s..."; sleep 5; }; \
    done \
    && apt-get update -y \
    && apt-get install -y --no-install-recommends \
        python${PYTHON_VERSION} \
        python${PYTHON_VERSION}-dev \
        python${PYTHON_VERSION}-venv \
    && CUDA_VERSION_DASH=$(echo ${CUDA_VERSION} | cut -d. -f1,2 | tr '.' '-') && \
    apt-get install -y --no-install-recommends \
        cuda-nvcc-${CUDA_VERSION_DASH} \
        cuda-cudart-${CUDA_VERSION_DASH} \
        cuda-nvrtc-${CUDA_VERSION_DASH} \
        cuda-cuobjdump-${CUDA_VERSION_DASH} \
        libcublas-${CUDA_VERSION_DASH} \
    && rm -rf /var/lib/apt/lists/* \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 \
    && update-alternatives --set python3 /usr/bin/python${PYTHON_VERSION} \
    && ln -sf /usr/bin/python${PYTHON_VERSION}-config /usr/bin/python3-config \
    && curl -sS https://bootstrap.pypa.io/get-pip.py | python${PYTHON_VERSION} \
    && python3 --version && python3 -m pip --version

# Install uv for faster pip installs
RUN python3 -m pip install uv

# This timeout (in seconds) is necessary when installing some dependencies via uv
ENV UV_HTTP_TIMEOUT=500
ENV UV_INDEX_STRATEGY="unsafe-best-match"
ENV UV_LINK_MODE=copy

# Workaround for triton issues (see main Dockerfile)
RUN ldconfig /usr/local/cuda-$(echo ${CUDA_VERSION} | cut -d. -f1,2)/compat/

# Install PyTorch with CUDA 12.8 support (required for vLLM compilation)
# Using PyTorch's official index for CUDA 12.8
RUN uv pip install --system torch --index-url https://download.pytorch.org/whl/cu128

# Copy the install script
# Note: Build from repository root: docker build -f docker/Dockerfile.dev -t yourusername/vllm-dev-base .
COPY docker/install-and-serve.sh /usr/local/bin/install-and-serve.sh
RUN chmod +x /usr/local/bin/install-and-serve.sh

# Explicitly call bash to avoid exec format errors (common when building on macOS)
ENTRYPOINT ["/bin/bash", "/usr/local/bin/install-and-serve.sh"]

